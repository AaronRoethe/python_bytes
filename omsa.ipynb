{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strcat_list(L):\n",
    "    assert type(L) is list\n",
    "    return ''.join(reversed(L))\n",
    "    \n",
    "# strcat_list(['abc', 'def', 'ghi']) == 'ghidefabc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceiling_fraction(a, b):\n",
    "    mul = a / b\n",
    "    result = int(mul)\n",
    "    if result == mul:\n",
    "        return result\n",
    "    elif (mul > result):\n",
    "        return (result + 1)\n",
    "# ceiling_fraction(0.3, 0.1) == ceiling(2.9999999999999996) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_lengths(s):\n",
    "    assert all([x.isalpha() or x == ' ' for x in s])\n",
    "    assert type(s) is str\n",
    "\n",
    "    list = []\n",
    "    ## if list not empty or only has spaces\n",
    "    if not s or s.isspace():\n",
    "        return list\n",
    "    ## split words by space count length of work append to new list\n",
    "    else:\n",
    "        words = s.split(' ')\n",
    "        for i in words:\n",
    "            list.append(len(i))\n",
    "        return list\n",
    "\n",
    "# count_word_lengths('zlvtqtvpjwohkvzsxxno bzp cabtcnibffyh lj') == [20, 3, 12, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_vector(x):\n",
    "    assert type(x) is list\n",
    "    d = {'inds': [], 'vals': []}\n",
    "\n",
    "    for index, i in enumerate(x):\n",
    "        if i != 0.0:\n",
    "            d['inds'].append(index)\n",
    "            d['vals'].append(i)\n",
    "    return d\n",
    "\n",
    "def decompress_vector(d, n=None):\n",
    "    # Checks the input\n",
    "    assert type(d) is dict and 'inds' in d and 'vals' in d, \"Not a dictionary or missing keys\"\n",
    "    assert type(d['inds']) is list and type(d['vals']) is list, \"Not a list\"\n",
    "    assert len(d['inds']) == len(d['vals']), \"Length mismatch\"\n",
    "    \n",
    "    ## Determine length of the full vector\n",
    "    i_max = max(d['inds']) if d['inds'] else -1\n",
    "    if n is None:\n",
    "        n = i_max+1\n",
    "    else:\n",
    "        assert n > i_max, \"Bad value for full vector length\"\n",
    "    \n",
    "    result = [0]*n\n",
    "    for i, v in zip(d['inds'], d['vals']):\n",
    "        result[i] += v\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_inds(d1, d2):\n",
    "    assert type(d1) is dict and 'inds' in d1 and 'vals' in d1\n",
    "    assert type(d2) is dict and 'inds' in d2 and 'vals' in d2\n",
    "\n",
    "    return list(set(d1['inds']).intersection(set(d2['inds'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = [\n",
    "    # First line is descriptive header. Subsequent lines hold data\n",
    "    ['Student', 'Exam 1', 'Exam 2', 'Exam 3'],\n",
    "    ['Thorny', '100', '90', '80'],\n",
    "    ['Mac', '88', '99', '111'],\n",
    "    ['Farva', '45', '56', '67'],\n",
    "    ['Rabbit', '59', '61', '67'],\n",
    "    ['Ursula', '73', '79', '83'],\n",
    "    ['Foster', '89', '97', '101']\n",
    "]\n",
    "\n",
    "grades\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thorny': [100, 90, 80],\n",
       " 'Mac': [88, 99, 111],\n",
       " 'Farva': [45, 56, 67],\n",
       " 'Rabbit': [59, 61, 67],\n",
       " 'Ursula': [73, 79, 83],\n",
       " 'Foster': [89, 97, 101]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dict mapping names to lists of grades.\n",
    "def build_grade_lists(grades):\n",
    "    s = {}\n",
    "    df = pd.DataFrame(grades[1:],columns=grades[0])\n",
    "    for index, i in enumerate(df.Student):\n",
    "        s[i] = list(map(int, df.iloc[index,1:]))\n",
    "    return s\n",
    "build_grade_lists(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    assert type (s) is str\n",
    "    return ''.join(ch for ch in s.lower() if ch.isalpha() or ch.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations # Hint!\n",
    "\n",
    "def update_pair_counts (pair_counts, itemset):\n",
    "    \"\"\"\n",
    "    Updates a dictionary of pair counts for\n",
    "    all pairs of items in a given itemset.\n",
    "    \"\"\"\n",
    "    assert type (pair_counts) is defaultdict\n",
    "    for a, b in combinations(itemset, 2):\n",
    "        pair_counts[(a,b)] += 1\n",
    "        pair_counts[(b,a)] += 1\n",
    "\n",
    "def update_item_counts(item_counts, itemset):\n",
    "    for i in itemset:\n",
    "        item_counts[i] += 1\n",
    "\n",
    "def filter_rules_by_conf (pair_counts, item_counts, threshold):\n",
    "    rules = {} # (item_a, item_b) -> conf (item_a => item_b)\n",
    "    for (a,b) in pair_counts:\n",
    "        assert a in item_counts\n",
    "        conf_ab = pair_counts[(a,b)] / item_counts[a]\n",
    "        if conf_ab >= threshold:\n",
    "            rules[(a,b)] = conf_ab\n",
    "    return rules\n",
    "\n",
    "def find_assoc_rules(receipts, threshold):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pair_counts = defaultdict(int)\n",
    "    item_counts = defaultdict(int)\n",
    "    \n",
    "    for i in receipts:\n",
    "        update_pair_counts(pair_counts, i)\n",
    "        update_item_counts(item_counts, i)\n",
    "        \n",
    "    return filter_rules_by_conf(pair_counts, item_counts, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e25b5007a15cbf93340b4f9138f1187145c0a10fd312404513e24be36619193e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('offsite': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
