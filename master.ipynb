{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_files(start, extract_extention, end):\n",
    "    # z = Path(f'data/load')\n",
    "    z = Path(f'{start}')\n",
    "    b = list(z.glob('*.zip'))\n",
    "    for i in b:\n",
    "        with ZipFile(i, 'r') as zip:\n",
    "            listOfFileNames = zip.namelist()\n",
    "            for fileName in listOfFileNames:\n",
    "                if fileName.endswith(f'.{extract_extention}'):\n",
    "                    zip.extractall(f'{end}')\n",
    "\n",
    "extract_files('data/load', 'csv', 'temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "### add to log module ###\n",
    "logging.basicConfig(filename='app.log',\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def df_len(name, df):\n",
    "    logging.info(f'len: {len(df)} \\t\\t {name}')\n",
    "\n",
    "### import into main() ###\n",
    "# import log.log as log\n",
    "# log.df_len()\n",
    "\n",
    "load = pd.DataFrame()\n",
    "df_len('load', load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "import holidays\n",
    "\n",
    "today = date.today()\n",
    "HOLIDAYS_US = holidays.US(years= today.year)\n",
    "HOLIDAYS_company = dict(zip(HOLIDAYS_US.values(), HOLIDAYS_US.keys()))\n",
    "\n",
    "del_list = (\"Washington\\'s Birthday\", 'Juneteenth National Independence Day','Columbus Day','Veterans Day')\n",
    "for i in del_list:\n",
    "    HOLIDAYS_company.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_DAY = timedelta(days=1)\n",
    "\n",
    "def next_business_day(start):\n",
    "    next_day = start + ONE_DAY\n",
    "    while next_day.weekday() in holidays.WEEKEND or next_day in HOLIDAYS_company:\n",
    "        next_day += ONE_DAY\n",
    "    return next_day\n",
    "\n",
    "def last_business_day(start):\n",
    "    next_day = start - ONE_DAY\n",
    "    while next_day.weekday() in holidays.WEEKEND or next_day in HOLIDAYS_company:\n",
    "        next_day -= ONE_DAY\n",
    "    return next_day\n",
    "\n",
    "def x_Bus_Day_ago(N):\n",
    "    B10 = []\n",
    "    seen = set(B10)\n",
    "    i = today\n",
    "\n",
    "    while len(B10) < N:\n",
    "        item = last_business_day(i)\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            B10.append(item)\n",
    "        i -= timedelta(days=1)\n",
    "    return B10[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've found pandas.isin or set.intersection()\n",
    "# Are very comparable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "def list_in_column(df, list):\n",
    "    filter0 = df['col_name'].isin(list)\n",
    "    df['new_col'] = np.where(filter0, 1, 0)\n",
    "    return df\n",
    "\n",
    "# pandas_df     = list_add['OutreachID'].squeeze()\n",
    "# pandas_series = list_add['OutreachID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_column(df):\n",
    "    df['OutreachID'] = df['OutreachID'].astype(str)\n",
    "    df['Matches'] = df.groupby(['PhoneNumber'])['OutreachID'].transform(lambda x : '|'.join(x)).apply(lambda x: x[:3000])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.csv as csv\n",
    "\n",
    "def data_proccess(location):\n",
    "    z = Path(f'{location}')\n",
    "    b = list(z.glob(f'*.csv'))\n",
    "\n",
    "    final = pd.DataFrame()\n",
    "    for i in b:\n",
    "        table = csv.read_csv(i)\n",
    "        df = table.to_pandas()\n",
    "        ### get name of file\n",
    "        # st = (str(i).split('\\\\')[-1][:-4])\n",
    "        st = 'file_name'\n",
    "        \n",
    "        ### filter what you want\n",
    "        # today = datetime.strptime(st, \"%Y-%m-%d\")\n",
    "        # yesterday = last_business_day(today)\n",
    "        filter1 = 'yesterday'\n",
    "        filter2 = 'properly'\n",
    "\n",
    "        ### create list\n",
    "        pastdue = df[df.Outreach_Status == 'Past Due'][['OutreachID']]\n",
    "\n",
    "        worked = df[df.Last_Call == filter1]\n",
    "\n",
    "        worked_ls = worked['OutreachID'].tolist()\n",
    "\n",
    "        worked_properly = worked[worked.Outreach_Status == filter2]\n",
    "        worked_properly_ls = worked_properly['OutreachID'].tolist()\n",
    "        try:\n",
    "            ### try and skip first file, second file uses \"last\"\n",
    "            print(st)\n",
    "            total_work   = last[last.OutreachID.isin(worked_ls)]\n",
    "            total_proper = last[last.OutreachID.isin(worked_properly_ls)]\n",
    "\n",
    "            total        = len(last)\n",
    "            work         = len(total_work)\n",
    "            count        = len(total_proper)\n",
    "            pct = count / work\n",
    "            \n",
    "            final[f'{st}'] = [total, work, count, pct]\n",
    "            last = pastdue\n",
    "        except:\n",
    "            last = pastdue\n",
    "    return final\n",
    "final = data_proccess('temp')\n",
    "final = final.T\n",
    "final.columns = ['Total PastDue', 'Total Worked', 'Next Day Schedule', '%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_tables(df):\n",
    "    df.pivot_table(index =['Daily_Priority', 'Daily_Groups', 'rolled'], \n",
    "                    columns ='Skill', \n",
    "                    values ='PhoneNumber', \n",
    "                    aggfunc = ['count'], \n",
    "                    margins=True,\n",
    "                    margins_name= 'TOTAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e25b5007a15cbf93340b4f9138f1187145c0a10fd312404513e24be36619193e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('offsite': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
